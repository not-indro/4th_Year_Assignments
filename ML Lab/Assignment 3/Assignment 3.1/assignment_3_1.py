# -*- coding: utf-8 -*-
"""Assignment_3 .1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jz3E4b7ns7D-s833-K_b4SFxzC631kya

##**Name - Indranil Bain**
##**Roll No. - 2020CSB039**
###**Assignment No - 03 (Titanic)**

**Download Titanic Dataset(https://www.kaggle.com/heptapod/titanic/version/1#) and do initial pre-processing and train a Logistic Regression for the classifier.**
"""

from google.colab import drive
drive.mount('/content/drive')

BASE_PATH = '/content/drive/MyDrive/CSV Files - COLAB/train_and_test2.csv'

import pandas as pd
from sklearn.preprocessing import OneHotEncoder
from sklearn. preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn. tree import DecisionTreeClassifier
import matplotlib. pyplot as plt

dataset = pd.read_csv(BASE_PATH)
dataset

dataset.dropna()

dataset.columns

dataset = dataset[
    filter(
lambda colName: "zero" not in colName,
        dataset.columns
    )
]
dataset = dataset.drop("Passengerid", axis=1)
dataset

from sklearn.preprocessing import OneHotEncoder

def one_hot_encode(X: "pd.DataFrame", col_name: "str") -> "pd.DataFrame":
    encoder = OneHotEncoder()
    encoded_df = pd.DataFrame(
        encoder.fit_transform(X[[col_name]]).toarray(),
        index=X.index,
        columns=encoder.get_feature_names_out()
    )
    X = X.join(encoded_df)
    X = X.drop(col_name, axis=1)

    return X

columns_to_encode = ["Pclass", "Embarked", "Sex"]

for column in columns_to_encode:
    dataset = one_hot_encode(dataset, column)

dataset

# Age and Fare needs to be standardized
from sklearn.preprocessing import StandardScaler
def standardize(df: "pd.DataFrame", col_name: "str") -> "pd.DataFrame":

    scaler = StandardScaler()

    df[[col_name]] = pd.DataFrame(
        data=scaler.fit_transform(df[[col_name]]),
        index=df.index,
        columns=[col_name]
    )
    return df

columns_to_standardize = ['Age', "Fare", 'sibsp', "Parch"]

for column in columns_to_standardize:
    dataset = standardize(dataset, column)

dataset

# Preprocessing Done, lets move to model
X = dataset.drop('2urvived', axis=1)
y = dataset[['2urvived']]

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y)

# make, train, and score the model
from sklearn.linear_model import LogisticRegression
model = LogisticRegression().fit(X_train, y_train.iloc[:,0])
accuracy = model.score(X_test, y_test)
print(f"accuracy = {accuracy}")

"""**2. Analyze and control the overfitting by varying the inverse of regularization strength parameter (0.1, 0.25,0.5, 0.75, 0.9) and plot the accuracy graph for the test set.**"""

import matplotlib.pyplot as plt

def get_acc_log_reg( X_train: "pd.DataFrame", X_test: "pd.DataFrame", y_train: "pd.DataFrame", y_test: "pd.DataFrame", c=1.0
) -> "float":
      return LogisticRegression(C=c)\
      .fit(X_train, y_train.iloc[:, 0])\
      .score(X_test, y_test)
inv_reg_strs = (0.1, 0.25, 0.5, 0.75, 0.9)
accuracies = [get_acc_log_reg(X_train, X_test, y_train, y_test, c) for c in inv_reg_strs]
plt.plot(inv_reg_strs, accuracies, '.-')
plt.title("Accuracy for Inverse Regularization Strength")
plt.xlabel(r"$\dfrac{1}{\lambda}$")
plt.ylabel("Accuracy")
plt.show()

pd.DataFrame(
    data = zip(inv_reg_strs, accuracies),
    columns=['inv_reg_str', 'accuracy']
)

"""**3. Using the same dataset train a Decision Tree classifier and vary the maximum depth of the tree to train at least 5 classifiers to analyze the effectiveness.**"""

from sklearn.tree import DecisionTreeClassifier
def get_acc_dec_tree(
    X_train: "pd.DataFrame",
    X_test: "pd.DataFrame",
    y_train: "pd.DataFrame",
    y_test: "pd.DataFrame",
    max_depth=1
) -> "float":
      return DecisionTreeClassifier(max_depth=max_depth)\
        .fit(X_train, y_train)\
        .score(X_test, y_test)
max_depths = range(1, 35)
train_accuracies = [get_acc_dec_tree(X_train, X_train, y_train, y_train, max_d) for max_d in max_depths]
test_accuracies = [get_acc_dec_tree(X_train, X_test, y_train, y_test, max_d) for max_d in max_depths]


plt.plot(max_depths, train_accuracies, ".-", label='Train')
plt.plot(max_depths, test_accuracies, ".-", label='Test')
plt.title("DecisionTreeClassifier Max Depth vs Accuracy")
plt.xlabel("Max Depth")
plt.ylabel("Accuracy")
plt.legend()
plt.show()